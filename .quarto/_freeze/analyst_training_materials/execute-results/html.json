{
  "hash": "c19d9cd57569a3531fbfc6d633b73712",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Simple Wrangling 101\"\nformat: \n  html:\n    code-fold: show\n    number-sections: false\n---\n\n\n::: {.cell}\n\n:::\n\n\n# Introduction\n\nThis document will show at a high level some common code that is useful for managing and wrangling data within RStudio.\n\nFor reference, we will assume that the data files are saved as Excel files (however we actually **highly recommend** saving social listening exports as CSVs).\n\n# Load in data\n\n### Read in individual file:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(readxl)\n\nmy_data <- read_excel(\"./PATH_TO_DATA/name_of_excel_file.xlsx\")\n\n## or you may have a csv\n\nmy_data <- read_csv(\"./PATH_TO_DATA/name_of_csv_file.csv\")\n```\n:::\n\n\n### Read in multiple files at once:\n\n:::{.callout-tip collapse=\"true\"}\n## Slack Overflow already answers this question\n\nCheck it out [here](https://slack-overflow-help.netlify.app/post/2022-05-20-reading_multiple_files/reading-in-multiple-data-files-at-once/)\n:::\n\nWhen you have multiple files with the same structure (same columns) that need combining, you can read them all in at once rather than doing it manually one by one. This is the case when we read in multiple exported files from the same social listening query.\n\nThe logic is straightforward: get a list of all the file paths, read each file, then stack them together into one dataset.\n\n#### Step 1: Get the file paths\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndirectory_path <- (\"~/Google Drive/Shared drives/SC -  Capture Intelligence/US Projects/Microsoft/829 - Microsoft Perceptions - Peak & Pits/Data/Copilot Data/Copilot All Up Data/\")\n\npaths <- list.files(path = directory_path, full.names = TRUE, recursive = TRUE, all.files = TRUE)\n```\n:::\n\n\n:::{.callout-tip collapse=\"true\"}\n## The `list.files()` function\n\nThe recursive = TRUE argument means R will look inside any subfolders too. If your files are all in one folder, you might want recursive = FALSE instead to be safe\n:::\n\n#### Step 2: Read all the files\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_files <- map(paths, read_excel)\n```\n:::\n\n\nThe `map()` function applies the same operation to each item in a list. Here, it's applying `read_excel()` to each file path, reading all your files in one go. Think of it as a more efficient way of writing multiple `read_excel()` commands.\n\n#### Step 3: Stack them together\n\n\n::: {.cell}\n\n```{.r .cell-code}\nraw_df <- all_files %>% \n  reduce(bind_rows)\n```\n:::\n\n\nAt this point, all_files contains all your data, but as separate datasets in a list. The `reduce() `function combines them using `bind_rows()`, which stacks datasets on top of each other (assuming they have the same column structure).\n\n# Joining datasets\n\nJoining is used when you have two datasets that share a common identifier[s] and we want to combine information from both. This is most commonly something like `universal_message_id`. If you are familiar with SQL, these work very similarly to SQL joins.\n\nThis can broadly be considered as \"adding extra columns to our existing data\", and in some special situations also leads to increasing the number of rows too.\n\nA common example of using this in our work is when we have social posts from Sprinklr in one dataframe, and then the scores/results of a model (say our Spam classifier model) in another dataframe, and we want to append these spam classification scores to the data from the Sprinklr export.\n\nThere are few different flavours of joins, and I think this resource by [Gauden Buie is absolutely brilliant in explaining how we can understand what they do](https://github.com/gadenbuie/tidyexplain) - read it! I have unashamedly adapted the below from his document\n\n### Left Join - Keep everything from the main dataset\n\n> All rows from `x` where there are matching values in `y`, and all columns from `x` and `y`.\n\nA left join keeps all rows from your main dataset and adds matching information from the second dataset. If there's no match, you'll get NA values. This is the most common join - use it when you want to enrich your main dataset without losing any of your original data.\n\n![](images/left-join.gif)\n\n::: {.cell}\n\n```{.r .cell-code}\ncombined_data <- main_dataset %>% \n  left_join(additional_data, by = \"shared_column\")\n```\n:::\n\n\n\n### Full Join - Keep everything from both datasets\n\n> All rows and all columns from both `x` and `y`. Where there are not matching values, returns NA for the one missing.\n\nA full join keeps all rows from both datasets, filling in NA where there are no matches. Use this when both datasets are equally important and you don't want to lose information from either.\n\n![](images/full-join_2.gif)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncombined_data <- dataset_a %>% \n  full_join(dataset_b, by = \"shared_column\")\n```\n:::\n\n\n:::{.callout-tip collapse=\"true\"}\n## The joining column\n\nThe `by = \"column_name\"` tells R which column to use for matching. If the columns have different names, use `by = c(\"col_a\" = \"col_b\")`.\n:::\n\n# Combining datasets (stacking and side-by-side)\n\nCombining is different from joining - it's about physically putting datasets together without needing a shared identifier.\n\n### Stacking datasets (adding rows)\n\nUse this when you have the same type of data from different sources that you want in one dataset:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstacked_data <- bind_rows(dataset_a, dataset_b, dataset_c)\n```\n:::\n\n:::{.callout-warning}\n## Beware of duplicates\n\nThis does not consider duplicates though- so if you have the same post in multiple datasets you will end up with multiple instances of this data point! \n:::\n\n### Side-by-side datasets (adding columns)\n\nUse this when you have different information about the same observations, in the same order:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwider_data <- bind_cols(dataset_a, dataset_b)\n```\n:::\n\n\n:::{.callout-warning}\n## Be careful with bind_cols()\n\nThis assumes the rows are in exactly the same order in both datasets. If they're not, your data will be mismatched! Usually safer to use a join instead.\n:::\n\n# The key difference:\n\n* Joining makes your data \"fuller\" by adding related information based on shared identifiers\n* Binding rows makes your data \"longer\" by adding more observations of the same type\n* Binding columns makes your data \"wider\" by adding more variables about the same observations\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}